# v1.1.0 Update Details

> Yejingram v1.1.0 update details.

This v1.1.0 update includes the following new features and improvements.

- Yejingram: https://yejingram.com/
- Yejingram (Development Preview): https://dev.yejingram.com/

> Notice: The development preview site may change at any time without prior notice. During active development, data loss caused by database schema changes or errors may occur and can be unavoidable. The Yejingram development team cannot be held responsible for this.

---

## New Features

- Added memory transfer feature
- Added manual message request feature (have the character initiate proactively)
- Enabled "Continue Response" in group chats
- Added profile image reference toggle
- Changed data storage method
- OpenRouter support
- DeepSeek support
- Support choosing tokenizer / payload format when using a Custom LLM

## Improvements

- Prevent accidental taps on message control buttons
- Improved initial page load speed (changed tiktoken loading method)
- Fixed various sticker issues (display resolution and more)
- Prevented END_OF_TURN errors
- Applied upper bound to reactionDelay

## Detailed Feature Introductions

### Memory Transfer

<img width="400" alt="image" src="https://github.com/user-attachments/assets/605c84f8-9d33-4182-93b8-50ea5fd85a10" />

You can move the accumulated memory from one chat room to another.

<img width="400" alt="image" src="https://github.com/user-attachments/assets/2674a3db-1744-4e85-bfc5-fa9ebca99e98" />

The original room's memory is not removed; you can manually delete everything if you wish. Transferred memory is inserted sequentially into the target room. With this you can, for example, carry over memory from a private chat when creating a new group chat.

### Manual First‑Message Feature

<img width="400" alt="image" src="https://github.com/user-attachments/assets/eb8e9d6d-a080-4d59-a271-b7812e2094ee" />

A "Request First Message" button has been added to the input panel menu. The character will send the first message based on the existing chat history and context!

Having the character randomly initiate without a user request at arbitrary times is technically infeasible, so we implemented a simulation mechanism that lets you trigger a proactive start instead.

<img width="400" alt="image" src="https://github.com/user-attachments/assets/dd192a12-b81d-4c2b-ad0d-b98c7ade1ef9" />

> Example of a character starting message

<img width="400" alt="image" src="https://github.com/user-attachments/assets/60646b76-209e-4673-9315-01c2cd374b8c" />

<img width="400" alt="image" src="https://github.com/user-attachments/assets/d1c06950-6b3b-44f3-81e9-de43d01b8f49" />

> Example of a context‑based proactive message

### Preventing END_OF_TURN Errors

<img width="400" alt="image" src="https://github.com/user-attachments/assets/43dbb5a1-9392-47d2-8b20-0222dfcd7922" />

We observed occasional END_OF_TURN errors when using Continue Response or in group chats.

This patch fixes those cases; you can now use "Continue Response" in group chats as well!

### Profile Image Reference Toggle

<img width="400" alt="image" src="https://github.com/user-attachments/assets/a58282e3-c561-452c-b54f-4b532be14288" />

Previously, profile images were always forced into the reference set for image generation. We've added a toggle button. When you hover (tap on mobile) the image and see the action tray: blue means reference ON, gray means OFF. The default is ON.

### Data Storage Method Change

<img width="400" alt="image" src="https://github.com/user-attachments/assets/4ebd948d-9d9f-41e6-8d94-6335bdeaf2c7" />

We found that on Chromium‑based browsers (Chrome, Samsung Internet, Edge, etc.) the app could crash once save data exceeded 100MB. To mitigate this, part of the storage approach has been changed. Existing save data remains fully compatible.

### OpenRouter / DeepSeek Support

<img width="400" alt="image" src="https://github.com/user-attachments/assets/1b99eb41-2448-4159-ae16-a556988baf67" />

<img width="400" alt="image" src="https://github.com/user-attachments/assets/cc91d2c0-173e-4013-8e99-2dd808d57ea4" />

You can now select OpenRouter and DeepSeek in the AI settings!

### Expanded Custom LLM Settings

<img width="400" alt="image" src="https://github.com/user-attachments/assets/406de045-9c9b-4902-a0c7-3a4818a9eb01" />

When using a Custom LLM you can now freely choose the tokenizer and payload format. Available options:

- Tokenizers: OpenAI (o200k_base, cl100k_base), DeepSeek, Llama2, Llama3, Llama4, Mistral, Qwen, Qwen3
- Payload: OpenAI, Anthropic, Gemini

### reactionDelay Upper Bound

When using structured output we saw cases where reactionDelay (the waiting time before showing a character's reply) became unnecessarily long because the LLM tried to be too "realistic".

<img width="400" alt="image" src="https://github.com/user-attachments/assets/f10856a5-b440-4f31-8f1c-76e87aff2aee" />

To prevent scenarios like waiting 3 hours for a character who "went to a meeting", we set an upper bound of 10 seconds for reactionDelay.

---

## Wrap‑Up

Thank you for always using Yejingram! We’ll keep working to deliver fun features and a comfortable experience.

You can contribute via the [Yejingram GitHub repository](https://github.com/YEJIN-DEV/yejingram). PRs are always welcome—looking forward to your contributions!
